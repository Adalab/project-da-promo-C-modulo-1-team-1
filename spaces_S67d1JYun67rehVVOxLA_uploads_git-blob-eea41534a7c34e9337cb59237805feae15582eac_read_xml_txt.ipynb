{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este archivo contiene el código necesario para poder leer los ficheros xml y txt.Debido a que este contenido aún no se ha visto en clase, pero se verá a lo largo del módulo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del fichero XML\n",
    "\n",
    "Nos devuelve una lista que contiene diccionarios con los diferentes elementos del archivo xml.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "[{'level_0': 1, 'index': 1'time': 784, 'age': '50-54', 'gender': '0' },\n",
    " {'level_0': 2, 'index': 2'time': 924, 'age': '22-24', 'gender': '0'},\n",
    " {'level_0': 2, 'index': 2'time': 575, 'age': '45-49', 'gender': '0'},\n",
    " {'level_0': 2, 'index': 2'time': 781, 'age': '45-49', 'gender': '0'}\n",
    " {'level_0': 2, 'index': 2'time': 1020, 'age': '25-29', 'gender': '1'}]\n",
    "\n",
    "\n",
    "> Recomendación: Aprender a tratar los datos de un elemento del diccionario, antes de intentar aplicarlo a todos los datos del fichero xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('data/data_xml.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "\n",
    "xml_list = []\n",
    "for child in root:\n",
    "    xml_dict = {}\n",
    "    for subchild in child:\n",
    "        xml_dict[subchild.tag] = subchild.text\n",
    "    xml_list.append(xml_dict) # Es una lista que contiene diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'level_0': '2', 'index': '2', 'time': '924', 'age': '22-24', 'gender': '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in xml_list:\n",
    "    if c[\"gender\"] == \"0\":\n",
    "        c[\"gender\"] = \"man\"\n",
    "    elif c[\"gender\"] == \"1\":\n",
    "        c[\"gender\"] = \"woman\"\n",
    "    elif c[\"gender\"] == \"2\":\n",
    "        c[\"gender\"] = \"nonbinary\"\n",
    "    elif c[\"gender\"] == \"3\":\n",
    "        c[\"gender\"] = \"prefer not to say\"\n",
    "    elif c[\"gender\"] == \"4\":\n",
    "        c[\"gender\"] = \"prefer to self-describe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': '35', 'time': '460', 'age': '30-34', 'gender': 'woman'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_list[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in xml_list:\n",
    "    a.pop(\"level_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del fichero TXT\n",
    "\n",
    "Nos devuelve una lista que contiene todos los elementos del archivo txt, cada elemento de la lista se toma como un único string. Cada elemento de la lista termina con \\n\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "['index_sql;Q3;Q4;Q5;Q6;Q7;Q8;Q9;Q11;Q12;Q13;Q14;Q15;Q16;Q17;Q20;Q21;Q22;Q23;Q24;Q25;Q26;Q32;Q33;Q34;Q35;Q41\\n',\n",
    " '1;Indonesia;Master’s degree;Program/Project Manager;20+ years;null, SQL, C, C++, Java;Python;null,   Notepad++  ,  Jupyter Notebook;A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc);null, None;Never; Matplotlib ;Under 1 year;  Scikit-learn ;Linear or Logistic Regression, Decision Trees or Random Forests;Manufacturing/Fabrication;1000-9,999 employees;1-2;We are exploring ML methods (and may one day put a model into production);null, Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data;60,000-69,999;$0 ($USD);;;;;Advanced statistical software (SPSS, SAS, etc.)\\n',\n",
    " '2;Pakistan;Master’s degree;Software Engineer;1-3 years;Python, C++, Java;Python;null,  PyCharm ,  Jupyter Notebook, Other;A laptop;null, Other;Never; Matplotlib ;I do not use machine learning methods;;;Academics/Education;1000-9,999 employees;0;I do not know;null, None of these activities are an important part of my role at work;$0-999;$0 ($USD);MySQL , MongoDB ;MySQL ;null, None;;Basic statistical software (Microsoft Excel, Google Sheets, etc.)\\n',\n",
    " '3;Mexico;Doctoral degree;Research Scientist;20+ years;Python;Python;null,   Spyder  ,  Jupyter Notebook;A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc); NVIDIA GPUs ;More than 25 times; Matplotlib ;5-10 years;  Scikit-learn ,   TensorFlow ,  Keras ;null, Dense Neural Networks (MLPs, etc), Convolutional Neural Networks, Recurrent Neural Networks;Academics/Education;1000-9,999 employees;0;I do not know;null, Do research that advances the state of the art of machine learning;30,000-39,999;$0 ($USD);;;;;Local development environments (RStudio, JupyterLab, etc.)\\n',\n",
    "\n",
    "\n",
    "> Recomendación: Aprender a tratar los datos de algunos de los elementos de la lista, antes de intentar aplicarlo a todos los datos del fichero txt.\n",
    " - Primer elemento de la lista:\n",
    "    lista[0] = 'index_sql;Q3;Q4;Q5;Q6;Q7;Q8;Q9;Q11;Q12;Q13;Q14;Q15;Q16;Q17;Q20;Q21;Q22;Q23;Q24;Q25;Q26;Q32;Q33;Q34;Q35;Q41\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_txt_reorder.txt','r') as file:\n",
    "    file_source = file.readlines() # Es una lista que cada línea del fichero txt como un string de todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q5/d6h10gfs1b33l8qy7mdmhspw0000gq/T/ipykernel_18776/2302367559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "file_source.remove(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q5/d6h10gfs1b33l8qy7mdmhspw0000gq/T/ipykernel_18776/3201940301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_source\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "for x in file_source:\n",
    "    x.remove(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin = []\n",
    "# for string in file_source:\n",
    "   #  if string != \" \" and string != \" \" and string != \" \":\n",
    "       # sin.append(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = str(file_source)\n",
    "type(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinenens = file.strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file2 = (file.replace(\" \",\"\")).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file3 = \" \".join(file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3191f930eabfdf0eb39086a24df618ea48425015dbb471465fb2c793fed20fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
